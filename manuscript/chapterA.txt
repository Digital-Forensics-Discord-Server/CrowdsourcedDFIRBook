# Chapter A - Scaling, scaling, scaling, a tale of DFIR Triage

{width: 30%}
![](ChXX/XXX.png)

C> By [Guus Beckers](http://discordapp.com/users/323054846431199232) | [LinkedIn](https://www.linkedin.com/in/guusbeckers/)

## What is triage?

While full disk analysis certainly has its place, triaging is an essential part of digital forensics. The purpose of triage is twofold, to cut down on the noise generated by the multitude of events on a host and to determine if deep-dive forensics is required. As time and computing power are precious resources, it is best not to waste them. Luckily there are a couple of concepts and tools that can help an investigator out on any level of the investigation. 

## What should be included in a triage?

Before getting nitty gritty with tools let's examine what's useful to include within a triage while dealing with the majority of cases. If specific cases deal with investigating well known artifacts do not hesitate to add them to your list of triage items. It is advisable to collect multiple sources of evidence type to get a through understanding of the case at hand, sometimes evidence will not be available within all data structures due to the specific behavior of the operating system while at other times an adversary might have deleted one of the available sources.  Without further ado, let's take a look at the list:

* A series of artifacts that keep track of locations of files on the disk or an file manager and any performed actions (renaming/deleting) , this can be a MFT or a list of locations that has been accessed.
* Artifacts which track the history of included files within a folder. 
* Any hibernation or swap files that have been written to disk, these particular artifacts can extend your window into the past by days or even weeks.
* Artifacts that indicate account usage, modification or deletion. 
* Artifacts that can clarify which applications have been installed or uninstalled at a particular date.
* Artifacts which can be used to prove application execution in the past. 
* Artifacts which can track network or data transfer by a particular process.
* Any available web browser history and a record of auxiliary actions such as initiated downloads. 
* Artifacts which track external events such as plugging in USB drives or/and other devices.
* Any available event logs that have been maintained by the operating system or relevant applications.
* Records of admin level activities on a system.

These artifacts can be used for initial analysis while further processing of a case takes place. 

## Forensic triage of one or a limited amount of hosts

Historically, to examine a computer, an investigator would manually collect all artifacts and going through them one by one. You would need to know the artifact, go to the folder containing the artifact, export and repeat the process for any relevant artifact. To say this takes a lot of time investment is an understatement. A couple of years ago KAPE was introduced to the forensic community. It is a standalone executable that contains a wealth of forensic knowledge on where artifacts live on a computer (knowledge you can extend by collaborating on the public GitHub). KAPE contains a set of definitions called targets. A target defines where a artifact lives on a system. Collecting it is as easy as ticking the a checkbox. Targets can also contain other targets. In this manner KAPE offers various triage targets, thereby allowing an investigator to perform triage of an entire host just by selecting a single target. The target collection can also be automated on endpoints by utilizing its command line counterpart.

The second part of KAPE covers analysis through definitions called Modules. A module can comb through data collected by a target and transform it to a file format thatâ€™s easy to ingest in other tools. It does this by interacting with third party tools that are part of a module. Any executable that uses a command line is a viable option. As an example, KAPE comes with the entire suite of Eric Zimmerman of forensic parsers (for an entire list check here) they cover most popular forensic artifacts. 

Of particular note for triage is the [KapeTriage Target](https://github.com/EricZimmerman/KapeFiles/blob/master/Targets/Compound/KapeTriage.tkape). The following description is provided at the time of writing:

KapeTriage collections that will collect most of the files needed for a DFIR Investigation. This Target pulls evidence from File System files, Registry Hives, Event Logs, Scheduled Tasks, Evidence of Execution, SRUM data, SUM data, Web Browser data (IE/Edge, Chrome, Firefox, etc), LNK Files, Jump Lists, 3rd party remote access software logs, antivirus logs, Windows 10 Timeline database, and $I Recycle Bin data files.

The KapeTriage collection can be post-processed using the [!EZParser Module](https://github.com/EricZimmerman/KapeFiles/blob/master/Modules/Compound/!EZParser.mkape). These parsers, also written by Eric Zimmerman, can be used to extract information from most common artifacts. Data will be made available in the CSV format.

These parsers (and other tools) can also be downloaded individually [here](https://ericzimmerman.github.io/#!index.md). Among the tools is Timeline Explorer, which is a utility which can open CSV files and has robust search and sorting options. A description and demonstration of Timeline Explorer is available at [AboutDFIR](https://aboutdfir.com/toolsandartifacts/windows/timeline-explorer/).

KAPE can be used during live investigations but also after a forensic image has been created. A recommended tool to use with KAPE is Arsenal Image Mounter. Among its capabilities is read-only and write-protected image mounting. Just point KAPE at the assigned drive letter and it can perform collection and analysis. 

Utilizing KAPE, collection and transformation of artifacts is brought down to a matter of minutes. This allows an investigator to perform triage to determine if  a deep-dive is required or perform triage while other forensic evidence is still processing. 

Another possibility when dealing with a single host is creating a custom content image using FTK Imager. You will be able to manually select the artifacts you want to collect using a graphical interface. Richard Davies covers this extensively in a video of his 13Cubed digital forensics YouTube series. It can be found [here](https://www.youtube.com/watch?v=43D18t7l7BI). 

### macOS and Linux

Similar tools like KAPE also exist for other operating systems. One of the tools that deals exclusively with macOS (and its mobile counterparts iOS and iPadOS) is [mac_apt](https://github.com/ydkhatri/mac_apt). It can extract a wealth of information from a macOS system and can deal with a variety of images and acquired data.  mac_apt can be used exclusively on forensic images. Fortunately, there exists a live response counterpart. Named the [Unix Artifcact Collector](https://github.com/tclahr/uac) (or UAC for short), it can acquire data from both macOS and a range of Linux distributions. Both tools are open-source and any contribution is welcomed. 

## Scaling up to a medium-sized subnet

The aforementioned tools work fantastically on a single host but how can we scale this to a subnet? 


macOS and Linux don't have similar tools but this shouldn't necessarily be a problem as can be seen in the next chapter.


## Scaling up to an entire network 

Individual hosts and small networks are discussed, what are the options when you deal with a massive network? A single tool can be used in that instance. Velociraptor is another additon to the open-source DFIR arsenal, upon its arrival in 2018 it quickly gathered a following and it isn't difficult to see why. Velociraptor is one of the most powerful tools in the DFIR community. For starters, it supports all the major operating systems, Windows, macos and Linux alike. What makes Velociraptor stand out is its distributed computing model along with a client/server approach. 

A Velociraptor instance consists of a server and a number of clients distrubuted through a (client) network. The agent creates a persistent connection to the server.

Analysts can use Velociraptor to:

* Retrieve any file on a connected endpoint in a forensically sound manner.
* Retrieve forensic artifacts from all connected endpoints with the push of a button. 
* Scan for IOCs utlizing both regex and YARA rules

