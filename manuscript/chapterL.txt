# Chapter L - Data recovery

When talking about data recovery we have to distinguish between 
 - Logical data recovery
 - Physical data recovery

{pagebreak}
## Logical data recovery

This is the type of data recovery which is offered by most forensics-tools and a lot of specialized programs. A logical data recovery can mean 

 - to restore deleted files,
 - to deal with a damaged filesystem-catalogue or
 - to repair damaged files

As good as forensics tools are for conducting an investigation, the most tools fall very short when handling corrupted filesystems. On the other side there are really great logical recovery tools like 

 - R-Studio ([https://r-studio.com](https://r-studio.com))
 - UFS-Explorer ([https://www.ufsexplorer.com](https://www.ufsexplorer.com))
 - DMDE ([https://dmde.com](https://dmde.com))

which are able to handle even severe damaged filesystems very well. The problem with forensics is the way such tools work. So-called data recovery programs analyse the whole drive and try to "puzzle" a filesystem together based on the found data.

That means that such a generated virtual filesystem is the interpretation of the data by the tool. It would be very hard in many and even impossible in some cases to follow along how the program got to the final result. As great as these tools are for recovering data and building a working folder-tree from corrupted filesystems as bad they are for forensics as the process which lead to the results are not always clear.

{pagebreak}
## Physical data recovery 

This category contains all kind of cases â€“ for example:

 - instable drives,
 - damaged PCBs (printed circuit boards),
 - firmware-issues,
 - head stuck on platters,
 - broken motors,
 - broken read-write-heads and even
 - damaged or dirty platters.

In case of flash-memory like memory-cards, pendrives or SSDs there are just 

 - electronical problems and
 - firmware issues, which made up the majority of the cases.

So, first of all we need to come to a conclusion how far does it make sense to go with data recovery when conducting a forensics investigation. I have thought about that for quite some time and I think the most forensics investigators will not want to build a fully fledged data recovery operation and start with cleanroom data recovery or dive very deep into firmware-repair but most forensic investigators probably don't want to outsource the imaging of a drive to a data recovery lab just because windows will drop the drive after it become instable.

I guess many will also want to handle a PCB-swap without a data recovery lab.

That is for sure an individual decision but going deeper into data recovery would need much more information than I could fit into one chapter. If you are interested in detailed introduction to professional data recovery I would recommend you my book [**Getting started with professional data recovery**](https://www.amazon.com/dp/B09XBHFNXZ/) (ISBN 979-8800488753).

After this limitation we can have a look at the right tools to fit that need. These are in my option: 

 - Guardonix ([https://guardonix.com/](https://guardonix.com/))
 - Rapidspar ([https://rapidspar.com/](https://rapidspar.com/))
 - Deepspar Disk Imager ([https://www.deepspar.com/products-ds-disk-imager.html](https://www.deepspar.com/products-ds-disk-imager.html))

The **Guardonix** is a quite powerful Writeblocker which allow you to handle instable drives by maintaining two independent connections - one to the PC which is maintained even when the drive is hanging or irresponsible and one to the drive itself. In this way the operating system is not aware of any issues the drive may have. With the professional edition of the tool the operator may even set a timeout to skip bad areas on the first pass.

The **Rapidspar** is a highly automated solution for easier data recovery cases. It allows just for a basic level of control but it can handle even some firmware-cases automatically. The tool is mainly designed for PC repair shops to offer semi-professional data recovery services but with the data acquisition addon it would become a quite interesting tool for a forensics lab. Just a pity the tool lacks even the most basic forensic functions!

It's good to have that firmware-capabilities but Rapidspar is not documenting anything it does and so it's absolutely a no-go for forensics. For entry-level data recovery operations is this tool a good choice but you may reach its limits quite fast because the tool support basically no manual control.

The **Deepspar Disk Imager**, for short DDI, is a PCIe-card which can handle the cloning of highly instable drives and this tool is the most professional data recovery tool but strictly limited to imaging. It is also ready for forensic imaging and it can calculate checksums on the fly. The DDI is also know in the data recovery industry for its great handling of unstable drives. 

The way a DDI reports errors is also great for diaglosis as the imaging progresses - errors are shown in the sector map be red letters. For eyxample an I means "sector ID not found" and if you just get reading errors with the letter I after a certain LBA the drive has most probably a translator issue (see firmware / error register).

Deepspar Disk Imager and Rapidspar have another advantage over the Guradonix / USB Stabilizer. These tools can build a headmap and ignore all sectors which belong to a defective head. This also allow you to identify bad heads and image good heads first which is saver. 


{pagebreak}
## How to approach a data recovery case

Before thinking about a data recovery attempt you would have to understand what is the cause of the issue and how to deal with it. This is very important because a wrong approach can damage drives.

That's why the first step is always the diagnosis! To properly diagnose an HDD, we need to understand the startup procedure, the firmware and the sounds a drive will make with certain issues. 

### HDD start-up process 

Put simply, we can divide the boot process of the HDD into the following steps:

1. The data from the ROM chip is loaded and the engine is started. 
2. If the motor rotates fast enough for an air cushion to form, the read/write head is moved from the parking position (inside the spindle or outside the platters on a ramp) onto the platters.
3. The first part of the firmware loaded from ROM contains the instructions on how the disk can load the remaining part of the firmware from the platters. This is located in an area on the platters, the so-called service area, which is not accessible by the user.
4. If the firmware could be fully loaded, the disk reports that it is ready for use. Knowing about this boot process can help us a lot in diagnosing problems. If a disk spins up, it most likely means that the ROM, MCU, RAM and motor control are OK and PCB damage can be ruled out with a high degree of probability.

### HDD firmware

A hard drive isn't just a dumb peripheral device, it's a small computer with a processor, memory, and firmware that's quite similar to an operating system. In the meantime, only 3 manufacturers, who have bought up many other competitors on their way, have prevailed in the market. Therefore, despite all the differences between the manufacturers, the firmware of hard drives follows a similar structure. The firmware is divided into different modules, which represent either data (G-List, P-List, S.M.A.R.T. data, ...) or executable code.

In general, the individual modules can be divided into the following categories:

1. The servo subsystem, which we can compare to drivers on a PC. On the HDD, for example, it's responsible for controlling and operating the head and the motor. The Servo-Adaptive Parameters (SAP) are there to correctly address these parts of the HDD. Damage in these modules can also result in the motor not running or the head making clicking noises.
2. The read/write subsystem provides the addressing (CHS, LBA, PBA, ...). This category includes Zone-Table, G-List, P-List, ...
3. The firmware core is responsible for ensuring that all modules and components work together and can therefore best be compared to an operating system kernel.
4. The additional programs are very individual and depend on the model family and manufacturer, just like user software on a PC. These include, for example, self-test and low-level formatting programs.
5. The interface is responsible for communication via the SATA/PATA port and in some cases also for communication via the serial port that some hard drives provide.

The higher layers build on the layers below. Therefore, the nature of a problem can already indicate at which level or levels you have to look.

A small part of the firmware is present on the ROM chip or directly in the MCU (Micro Controller Unit). This part can be imagined as a mixture of BIOS and boot loader. It runs a self-test and then uses the head of the drive to load the rest of the firmware from the platters.

We find the remaining parts of the firmware in the so-called service area (SA) on the platters. This is a special area on the platters that is not accessible to a normal user. Usually, there are at least two copies, which can then be read via head 0 and head 1.

To access the service area we need special software like **WD Marvel** and **Sediv** or special hardware tools like **PC-3000**, **MRT**, **DFL SRP** or **DFL URE** (but URE is quite limited here).

These are not tools that can be learned by trial and error. Any incorrect use of various options can damage the hard drive. If you try to repair a healthy module, there is a high chance that it will be damaged afterwards and if it is a critical module, the HDD will not start anymore.

Also, the options offered vary depending on the vendor and model of the hard drive, so you can only perform certain actions on certain models. The learning curve of these tools is extremely steep and a lot depends on the tool used. Mastering a firmware tool takes a lot of practice and experience, which you build up over the years working with other DR technicians, attending training courses and conferences, and working with support on specific cases.

So this area of data recovery requires the greatest learning effort and the purchase of the most expensive tools represents only a very small part of the cases. Therefore there are quite a few laboratories that only treat these firmware problems to a small extent themselves and outsource harder cases. MRT offers, for example, that their technicians solve firmware problems via remote maintenance and charges 50 USD in case of a successful data recovery. DFL offers its customers up to 5 support requests per month for free, just like Ace Labs.

The possible causes of firmware problems are just as varied as the solutions:

 - G list or S.M.A.R.T. logs fill up or run into other modules (similar to a buffer overflow in RAM) and partially overwrite them.
 - The data of the module was written incompletely or is damaged due to other errors (e.g. failed sector).
 - The data in the ROM chip does not match the data in the service area.
 - The ROM chip is mechanically damaged or short-circuited.
 - etc.

If we go back to the start-up process of the HDD, then from the perspective of the firmware, the ROM chip is read first, then the servo subsystem, then the read/write subsystem and then everything else is loaded to also provide access to the user data.

If this process is not completed, it is not uncommon to have read and write access to the service area but not to the user data.

Most of the commands that allow access to the firmware are manufacturer-specific and unfortunately not documented - at least not publicly!

There are some data recovery laboratories that have access to confidential company-internal documents of the manufacturers with the documentation of various firmware versions, manufacturer-specific ATA commands or the like and sometimes also pass them on to others on the sly.

In many areas, leaked information like the ones mentioned above or reverse engineering is the only source of information.

Some basic information can be found online as well as in firmware tool manuals. Anyone who starts looking into this will have to invest some time here and read up accordingly whenever new information is encountered.

### Important parts of the firmware

As we already know the servicearea is divided into modules, of which certain modules are essential for the operation of the disk and others are not necessary.

If a disk cannot read data from copy 0, then it will usually try to point to copy 1. It can therefore take a while before a hard disk reports that it is ready. The firmware often makes several read attempts before switching to the next copy. The more modules are damaged, the longer this can take. I've seen hard drives which needed several minutes but become ready.

Some modules are unique to each disk and other modules are the same for all disks with a specific firmware version, or even for all disks of an entire model range.

Damaged modules that are not individual for each hard disk can often be loaded from donor disks or obtained from the Internet and then used to repair a customer disk.
Within the firmware sectors, there is another type of addressing - the so-called UBA addressing (Utility Block Address). Sometimes it's also called the Universal Block Address - that's because manufacturers of data recovery tools don't have access to the firmware developer's documentation and find out most of it by reverse engineering and then just naming things themselves. That is why the individual terms also differ between the individual firmware tools (PC-3000, MRT, DFL).

The following parts can be found in one or another way on each HDD firmware and it's very important to understand these things to recover date from an HDD.

**P-List**

This list includes sectors that were defective at production time. That's why it is called primary, permanent or production time list. That the hard disk is not forced to execute jumps with the head from the beginning due to unmapped sectors, the sectors that were already defective at production time are skipped and the numbering is structured in such a way that it is consecutive from sector 0 to N and the defects in between are simple are skipped:

![12.1 - P-list](resources/UnfinishedChapters/ChL/P_List.png)

This also show how the PBA (physical block addressing) differs from LBA (logical block addressing). The P-list is one of that modules that are unique to each hard drive and cannot be replaced.

**G-List**

The growing defects list or G-list is a list of sectors that fail during operation. To avoid having to move several TB of data by one sector in the worst case, a defective sector is replaced with the next free reserve sector during operation:

![12.2 - G-list](resources/UnfinishedChapters/ChL/G_List.png)

If a read- or wite- error occurs, the sector is marked as defective and mapped out on the next opportunity when the disk is idle. This happens in so-called background-processes which start in most cases after 20 secounds of idle-time.

That's why professional  data recovery labs disable unnecessary background activities in order not to corrupt data and save the disk unnecessary work. If we do not have that option, we need to pay attention to the drive and don't let it run then it is not in use.

If the G-List is lost, data will be damaged because sectors mapped out during operation are reset to the old locations. However, this can also be used in a forensic investigation to recover old data fragments in the sectors which got mapped out, even after the disk has been wiped.

However, this also means that a hard disk becomes slower and slower the more unmapped sectors there are because the more often the head has to make jumps to the new location of a LBA when reading the data.

Depending on the manufacturer / model series, this is slightly different. Many disks have smaller reserve areas distributed over the platters to minimize any necessary jumps and the associated loss of performance. 

**Translator**

The translator is the module that converts the LBA address into the corresponding arm movement. If the translator is defective, we have no access to the data. It is relatively easy to test whether the translator has a problem.

**Zone tables**

Zones make it possible to use a different number of sectors per track.

The old CHS (Cylinder, Head, Sectors) addressing assumed that each track or cylinder had the same number of sectors. Since the radius of the cylinders decreases with each step in the direction of the spindle, a lot of space would be wasted if the outer cylinders had the same number of sectors as the inner cylinders.

Here is the simplified graphic representation for comparison:

![12.2 - HDD with and without zone tables](resources/UnfinishedChapters/ChL/CHS_vs_Zones.png)

What is graphically displayed here is saved by the zone table in a form that can be used by the firmware. Without this data, it would not be possible to calculate the location of a specific LBA address is on the platters!

**Servo parameters / Servo adaptive parameters**

This data is used to fine-tune the head and is unique to each hard drive. Incorrect data can lead to the head no longer reading or only reading with reduced performance.

There are often different data sets for the service and user area.

**Security-relevant data / passwords**

Some encryption methods save the passwords on the hard disk in the service area. In these cases, passwords can be easily read out or removed with access to the firmware modules.

**Firmware / overlay code**

To put it simply, these are program instructions that are loaded into the main memory of the HDD when required.

As with very old computers, the working memory of hard disks is very limited and therefore developers have to be careful with it.

Depending on the context in which these terms are used, it is code that is loaded when required, like a DLL, or code that is loaded from the service area and overwrites the first rudimentary program parts loaded from the ROM.

In any case, the term is more common for special code parts that are loaded into the RAM of the HDD when needed and then replaced with other code parts in the RAM when the function is no longer needed.

**S.M.A.R.T. data**

S.M.A.R.T. was developed to warn the user before a hard drive fails. Often S.M.A.R.T. however, is the cause of such a failure.

When the S.M.A.R.T. log becomes corrupted and contains invalid data that the disk cannot process, causing the disk to fail to fully boot and never report that it is ready.

Since S.M.A.R.T. is not essential for operation, deleting the S.M.A.R.T. data and disabling the S.M.A.R.T. functions is the simplest solution to this problem.

**Serial number, model number and capacity**

In many cases, the serial and model numbers are read from the service area. If a hard drive shows the correct model and serial number, as well as capacity and firmware version, this is a very strong indicator that the head can at least read the service area.

If there is no access to the user data, but the the obove mentioned values are displayed correctly (data recovery technicians call that a "full ID"), you can determine with a high degree of certainty that at least one head is OK and can read.

**Safe mode**

Hard drives have a safe mode that they go into if some part of the firmware is corrupt. This is manifested by multiple clicks, shutting down and restarting the motor and then starting again.

Smaller 2.5" laptop drives often just shut down and don't try multiple times.

PC-3000 recognizes this problem itself and shows us that a hard disk is in safe mode.

You can also put the hard drive into safe mode on purpose. The hard disk then waits for suitable firmware to be uploaded to the RAM. This is also referred to as a "loader".
Once the loader has successfully uploaded and is running, you can start repairing corrupted firmware modules.

### Staus and error registers

Besides the noise and behaviour of a drive there are status informations which can be desplayed by some data recovery tools like the DDI, MRT, PC-3000 and DFL. But there are also some free tools which show these status flags like Victoria ([https://hdd.by/victoria/](https://hdd.by/victoria/)) or Rapid Disk Tester ([https://www.deepspar.com/training-downloads.html](https://www.deepspar.com/training-downloads.html)).

![12.3 - status flags from MRT](resources/UnfinishedChapters/ChL/status_flags.JPG)

These indicated status LEDs also help with diagnostics.

**BSY** means "busy" and indicates that the disk is busy. It's OK to leave an HDD or SSD on BSY for a while and wait, as long as the disk isn't making any weird noises! BSY is the first status that the HDD shows before the firmware is fully loaded. Here I monitor an SSD with a thermal camera and an HDD with a stethoscope.

**DRD** stands for "drive ready" and means that the hard disk is ready to receive commands.

**DSC** means "drive seek complete" and indicates that the head has moved to a specific position.

**DWF** means "drive write fault" and should always be off. 

**DRQ** means "data request" and is set when the data carrier is ready to transfer data.

**CRR** stands for "corrected data" and should always be off.

**IDX** means "index" and should always be off.

**ERR** stands for "error" and indicates if an error occurred with the previous command. The error is then described in more detail by the following error codes:

 - **BBK** (bad block)
 - **UNC** (uncorrectable data error)
 - **INF** (ID not found)
 - **ABR** (aborted command)
 - **T0N** (Track 0 not found)
 - **AMN** (Address mark not found)

The abbreviation can differ hereby from tool to tool.

### Diagnosing the issue

Till now you have learned how to get a better picture of the inner processes of an HDD so it's time to use that knowledge practically...

It would be hard to describe some of the sounds you may hear when a drive has a certain issue â€“ luckily a data recovery lab has recorded a lot of sound samples and offer then on there homepage. You can find the files here: [https://datacent.com/failing_hard_drive_sounds](https://datacent.com/failing_hard_drive_sounds)

If a disk spins up but then gets stuck in the **BSY** state, this indicates that parts of the firmware are corrupt or unreadable. Or background processes are running on the hard disk that hangs or takes a long time to finish. It can be also due to issues reading the firmware from paltters. If the drive sounds OK then wait a few minutes and see if the drive come ready. If a drive is not ready within 10-15 minutes, then it's highly unlikely it will become ready when you wait longer. Most likely you will need a firmware-tool and the proper knowledge to deal with that issue.

If a disk reports readiness but reports unusual values - eg: 0 GB or 3.86 GB for the capacity. Then an essential part of the firmware may be corrupted or only the part from the ROM chip could be read. It's also possible that the ROM chip is wrong (eg an amateur attempting a data recovery and just swapped the PCB) or the head is damaged and can't read the data from the service area or a early loaded firmware module is corrupted.

If the head keeps clicking, it can sometimes indicate a firmware problem or the wrong ROM chip on the PCB. But much more likely the head could be defective and not find the service area because it can no longer read anything. I've also seen these symptoms when the ROM chip was defective.

The more experience you gain, the better you will be at assigning noises, status LEDs and other indications from the hard drive to a specific problem. You don't learn data recovery overnight!

Before cloning the drive try to read the first sector, if that works, read the last sector and at least one sector in the middle of the disk. If you can read the drive till a specific LBA and all sectors after this LBA it could either be a defective head or the translator (sometimes also called the address decoder).

A defective head mean you can read till some point then you have a group of unreadable sectors and after the sectors of the defective head you can read again some data. If the translator is damaged you can't read after a certain LBA not a single sector.

To test which issue you may face you can try to read more sectors (maybe 10 or 15) distributed across the entire surface.

Another good indication are the S.M.A.R.T. values. The fact you can read the S.M.A.R.T values itself mean that the heads is good and able to read at least the service area and it also mean that the firmware is loaded at least till the S.M.A.R.T. module which mean basically all the critical modules are loaded.

The values itself tell you more important information:

  - **0x05  (Reallocated Sectors Count)** tells you how much bad sectors got reallocated
  - **0x0A (Spin Retry Count)** tells you how often the drive try to spin up multiple times toll it reach the desired rmp. This can indicate a machincal problem.
  - **0xBB (Reported uncorrectable Error)** tells you how many Errors could not be corrected by ECC. This can indicate fading of the magnectic load on the platters when the drive was long time not in use or degradation of the head or magnetic coating.
  - **0xBC (Command Timeout)** tells you the how often a Timeout occure while trying to execute a command. This can indicate sometimes problems with the electronics or oxidized data connections.
  - **0xC4 (Reallocation Event Count)** tells you how many sector reallocations where done successfully and unsuccessfully.  
  - **0xC5 (Current Pending Sector Count)** tells you how many sectors are waiting for reallocation. This value is very important for forensics! In case the drive will be idle for longer then 20 seconds this sectors can get reallocated which could alter data.
  - **0xC6 (Uncorrectable Sector Count)** tells you how many sectors could not corrected by ECC. The same as for 0xBB applies here.
  - **0xC9 (Soft Read Error Rate)** tells you how much not correctable software read errors occurred. The same as for 0xBB applies here.

In the context of **0x09 (Power On Hours Count)** you can conclude if the errors indicate a production-issue and that for likely a rapid degradation of the drive (little amount for hours) or the normal degradation over time in case the drive was in use for many hours.

### The forensical importance of S.M.A.R.T. data

I recommend getting the S.M.A.R.T. values before and after imaging. As you have learned till now â€“ the drive will reallocated bad sectors when it stays to long in idle. This can cause big issues then someone else calculate the checksum of the drive and it do not match up with the checksum in your report.

Even if you pay attention that the drive will never be in idle some other investigator may let the drive idle for a few minutes before calculating the checksum and thus this person alter the data. In such cases it's wise to have the S.M.A.R.T. values reported before and after imaging that you can explain why the checksum don't match up anymore.

In a data recovery case, some drives may have troubles to boot up like a minor scratch in the service area which is very hard on the head when starting. So, you would not want to start the drive multiple times as you can not know if the head or drive may survive the next start. If you are not able to deactivate background-processes like the reallocation of sectors, it's in some cases necessary to accept the smaller risk and rather loose a few sectors then the whole drive. Of course it would be the best way to outsource such a case to a professional data recovery lab but this is not always an option.


{pagebreak}
## Imaging of unstable HDDs

The imaging of unstable HDDs follows an easy approach - first we want to get the low hanging fruits with a low stress-level for the drive and then we are going to fill the gaps and read the problematic areas.

In more technical terms we need multiple imaging passes. In the first pass we use a small read timeout (300 â€“ 600ms) so that the head is not working to long on bad sectors. The reading-process will look then like that:

![12.4 - Simplified graphical representation the the read process](resources/UnfinishedChapters/ChL/Read_Timout.png)

If the data is delivered by the drive before the read timeout occurs then we save the data and continue to read the next block. If the timeout is reached the imaging device will send a reset command to cancel the internal read retries of the drive and then the imaging continue with the next block.

That is why the read timeout is the most important setting for handling instable drives! As longer a head is trying to read bad sectors as more the head can get damaged over time.

There are some drives which have bigger areas of bad sectors â€“ in such cases it is wise to ship a certain amount of sectors to overcome the bad areas. If we are not sure the drive has experienced a drop or head-crash we can't be sure there is no miner scratch on the surface. That's why I set in my first imaging passes always a high amount of sectors to skip (e.g. 256000) after a read error. This ensures that we skip over bad areas or tiny scratches very fast.

If you have read all good sectors with a short read timeout you can run the next imaging pass with a longer timeout and re-read all blocks which are skipped in the last pass.

If there are mainly skipped blocks on one pass and just occasionally read blocks then you have to increase the timeout till you read at least 2/3 of blocks. 

As you increase the read timeout with each pass, you should decrease the amount of skipped sectors after a read timeout or read error with each pass.

If your tool allows to create a headmap I would strongly suggest to do that before imaging. So that you can see if there is a bad head or even a completely broken head so you can skip that head in the first pass.

In case a drive will not be identified but got stuck in BSY it may be one of the commands used to initialize the drive which cause the drive to hang. That's why DDI allow to configure the commands used to initialize the drive. Sometimes a non-standard initialisation procedure will allow a drive to become ready:

![12.5 - DDI confoguration of drive initialisation command sequence](resources/UnfinishedChapters/ChL/DDI_Initialisation.JPG)

In case you change the identification procedure and the drive become ready but you can not image a single sector you have to try another identification procedure so that the drive does not just become ready but also give you data access!

Some imagers allow us to deactivate unnecessary functions of the drive like S.M.A.R.T., caching, sector reallocation, etc.

The deactivation of unnecessary things makes the imaging not just a bit faster but also much lighter for the drive. If S.M.A.R.T. is enabled, the drive will have to update the S.M.A.R.T. data each time it hits a bad sector. This force the head to jump to the service area and write data and that is not just more "stress" for the drive but also a risk. In case the drive would write bad data into the firmware module the drive can develop a firmware issue and don't boot anymore. Or the module can grow to big and damage the following module in the service area resulting in the same problem.

DDI has an option in the menu to deactivate such things (Source -> Drive Preconfiguration). This option deactivates things based on a pre-set from DDI but it don't allow you to select specific things. A fully fledged firmware-tool like MRT will allow you to do that:

![12.6 - MRT edit HDD ID dialogue](resources/UnfinishedChapters/ChL/MRT_Edit_HDD_ID.JPG)

The next possible setting may be the read-mode. We can use the faster UDME-Modes or the older and slower PIO-Mode if some hardware-imager will allow you to set these things like DDI, MRT, DFL or PC3000:

![12.7 - MRT read mode selection for an imaging task](resources/UnfinishedChapters/ChL/MRT_read_mode.JPG)

![12.8 - DFL DE read mode selection for an imaging task](resources/UnfinishedChapters/ChL/DFL_DE_read_mode.JPG)

The other modes like "Read, ignore CRC" are helpful in some cases â€“ here does the DDI a fabulous job. MRT does exact what the name suggests and read the data and wite it to the image or target drive no matter if the checksum of the sector matches. DDI read the sector in this mode multiple times and does a statistical analysis for each bit to get the most probable result instead of the first result the drive delivers. Each way is useful when the sector checksum is corrupted. In case a very weak head gives you bad data the statistical analysis of Deepspar's DDI would ensure that you get the best possible result but the trade-off of this would be a longer imaging-duration and much more stress on the head. That's why this is not an option you should use on the first pass but rather on the last imaging pass!

The idea behind using a slower read-mode is simple! An unstable drive can read maybe more stable in a slower speed. There are also cases where a firmware-part is damaged and the drive is highly unstable in UDMA for example but PIO would use another fully functional part of the firmware. Different read-commands also apply different procedures and, in some cases, you may be able to read bad sectors with another read-mode. Thatâ€™s why I recommend using different Read-modes in different passes.

The same apply for the read method (LBA, CHS, ...)!

The last option I want to mention is the imaging direction - forward or backward. In backward-imaging the drive is bypassing the cache and that's how you can overcome issues with the cache. That makes the imaging-process also much slower but slow imaging of good data is much better then fast imaging of data corrupted by the cache!

You can also see that different Tools offer different levels of control and different options. That's why we have most of the tools in our data recovery lab so we can choose the best tool for a job.

If I need to use the ignore CRC option, I would use for sure the DDI and not the MRT and DFL would not even give me that option at all. In case of mode-control DFL would give me more granular control.

That's also why a full-blown data recovery operation need a lot of different tools to have these options.

There are even more options to optimise the imaging. One of them would be the reset-commands. You may choose between hardware- and software-reset. Some drives may process one of that resets much better or faster than the other. I have even seen drives freezing when issuing the "wrong" reset command. 

### Practical example â€“ imaging a WD40NMZW with the Guradonix writeblocker

This is a drive I have recently recovered and the drive is highly unstable and is has a lot of bad sectors with a very weak head because the local PC repair shop has tried to recover the data by scanning the drive with a data recovery program which tool multiple days because of internal read-retries. Finally, the head got that much damaged that Windows start to hag when the drive is directly connected after a while Windows just drops the HDD.

This is also a good example for the dame a wrong data recovery approach can cause. At least the head is not totally dead â€“ so we have something to work with.

I were thinking about that example for a while and I think the most useful tool for a forensics lab would be the USB stabilizer. This tool is the "bigger brother" of the Guradonix writeblocker and it allows you a bit more control. It can be also used with firmware-tools so if you are thinking about data recovery this would be my recommendation for the lowest you should go.

If not used for data recovery the USB Stabilizer works as a USB-writeblocker and as you may know basically every storage device can be adapted to USB. So, it you are starting out in forensics this the tool which gives you the most options.

That makes this quite an extreme example â€“ we have the lowest-end tool and a data recovery case which is at least a medium to a higher difficulty imaging job. So that will be also a good test to see what the USB Stabilizer can do!

This case also gives me the opportunity to demonstrate another procedure in data recovery. A USB to SATA conversion for western digital drives. This is basically the same procedure as for a PCB-swap, we just swap a USB-PCB with a SATA-PCB.

To do that we should look at what data contains the ROM-chip on the PCB:

![12.9 - List of firmware module on a Western Digital ROM chip](resources/UnfinishedChapters/ChL/ROM_List.PNG)

As you see on the image the modules 0x30 and 0x47 contain the service-area (SA) translator and SA adaptive parameters. These two modules make each ROM-chip unique for each drive. That's why we have to transfer the ROM-chip from the original PCB to the new PCB.

That is not just valid for WD drives but for each manufacturer!

To check which chip is the ROM-chip I usually search the PCB-Number (2060-xxxxxx-xxx Rev x in terms of WD PCBs) + the word donor in Google Images. This brings usually images from specialized retailers of donor drives and PCBs. Some of them have marked the ROM-chips on their images.

I validate this also by googling the datasheet of the marked component. If that is indeed a SPI flash chip or something like that you have confirmed that this component is the ROM chip. 

There are some PCBs where you have an empty space for the ROM-chip. This mean the data is in the MCU (micro controller unit) and the ROM-chip gets used in later versions to patch the MCU with newer code.

In that cases you have to transplant the MCU from the original PCB without a ROM-chip and remove the ROM-chip from the donor PCB if there is one. Usually, you have also another component on the PCB which act as a switch to activate the ROM-chip. This have to be also removed.

In case the original PCB have a ROM-chip but the donor PCB don't, you have to transfer the ROM-chip and the 2nd component used as a switch.

![12.10 - ROM-chip transfer for PCB-swap](resources/UnfinishedChapters/ChL/DSC_4390.JPG)

This is often needed for imaging as a USB interface is not that stable as SATA but that gets also used in case a PCB is damaged.

Now I am using a **Axagon Fastport2** adapter to connect the HDD wo my USB Stabilizer. So, I am basically reverting the SATA conversion I had done to image the drive with MRT.

The first step is to get the drive to ID. To see if the drive is recognised, I open the **Log**-Tab in the USB Stabilizer Application:

![12.11 - USB Stabilizer Log-tab](resources/UnfinishedChapters/ChL/usb_stabi_log.PNG)

Then we have to select the drive in DMDE:

![12.12 - DMDE drive selection and USB Stabilizer Settings-tab](resources/UnfinishedChapters/ChL/DMDE_select_drive.PNG)

I have chosen DMDE ([https://dmde.com](https://dmde.com)) because the tool is pretty cheap, powerful and it is also great for analysing filesystems. That make that program a good choice for data recovery and even quite useful for forensics.

In the **Settings**-tab of the USB Stabilizer application are controls for the device-type (HDD or SSD) which effect the handling of resets, the reset type (software, hardware, controller, â€¦) and finally the read timeout.

So, we have the most important setting for imaging speed and stress-level of the drive as well as resets which can cause instability issues. That means we have the most basic controls. The checkbox "Turn Off Drive if Inactive" is also helpful to prevent that the reallocation of bad sectors will damage data and the drive before we start another imaging pass.

With the **Commands**-button you can issue resets manually or you can log the S.M.A.R.T. data as I would suggest before and after forensic date acquisition. 

To sum that up so far, we are using here the lowest end data recovery tool with a cheap data recovery program on a medium till moderate difficult case for professional data recovery tools. A case which took a 5x more expensive and much more flexible tool over a week to image.

After we select the disk we see the following initial scan dialog:

![12.13 - DMDE initial scan](resources/UnfinishedChapters/ChL/DMDE_scan.PNG)

DMDE try to read the first sectors and this drive have a bad LBA 0 (MBR) which can't be read. DMDE sees that because I have set the USB Stabilizer to report read errors back to the OS so that the Software can log them correctly.

This is why DMDE display the following error:

![12.14 - DMDE read error](resources/UnfinishedChapters/ChL/DMDE_error.PNG)

You can select "Ignore all" and cancel the further processing of the partition table. First, we want to clone the drive and then we run the logical data recovery on the image file.

DMDE allow you to control a few other parameters while imaging. First, you need to set the LBA range and the target:

![12.15 - DMDE imaging settings - Source and destianation](resources/UnfinishedChapters/ChL/DMDE_settings_1.PNG)

This dialog should be pretty self-explanatory. DMDE just allow you to create a RAW-image. More advanced tools will allow you to do create VHD, VHDX or some other kind of sparse-files which will save you a lot of space on the target drive.

The next settings need to be done in the **Parameters**-tab:

![12.16 - DMDE imaging settings - Parameters and Source I/O Parameters](resources/UnfinishedChapters/ChL/DMDE_settings_2.PNG)

First, you should create a log-file. This file stores an overview about read, unreadable and skipped sectors. You can also select to image in reverse in that dialog. I unchecked "Lock the source drive for copy" as the USB Stabilizer act as a writeblocker anyway. 

For the 2nd pass you can select here also to retry bad sectors. This make sense because many of the bad sectors will be retrieved with a longer read timeout.

A click on the **Parameters**-button opens the 2nd window. Here you can select in the **Ignore I/O Errors**-tab which fill-pattern should be used for bad and skipped sectors and how many sectors will be skipped after a bad sector. This setting allows you to overcome bad areas quicker.

From my experience with that drive, I choose 25600 for the first pass. In MRT I used 256000 in the first try but I realized that I ship so much to much sectors and I realised that I there are all over the surface bad areas. So, I was pretty certain that we are not dealing with local issues like a minor scratch. That's why I lowered the skipped sectors on MRT after the 15 or 20% mark also to 25600.

I still keep it quite big for the first pass as I realized with a much smaller setting that the bad areas are 20000 â€“ 80000 sectors wide â€“ so 25600 was a good size to skip them in 1 to 4 steps. As I told - get the low hanging fruits first because you never know if the drive may die on you in the first pass!

DMDE shows you the total number of read and skipped LBAs:

![12.18 - DMDE imaging progress](resources/UnfinishedChapters/ChL/DMDE_imaging_running.PNG)

The **Action**-button let you cancel the imaging or change the I/O settings while you imaging. That let you finetune skip-settings on the fly.

The **Sector Map**-tab shows the imaging progress:

![12.18 - USB Stabilizer first imaging pass](resources/UnfinishedChapters/ChL/imaging_1.PNG)

You see here very well how the imaging works â€“ the spikes where the drive read with decent speed is broken up by bad ares which got skipped. 

For the 2nd pass I use the following settings:

![12.19 - DMDE imaging settings - Source and destianation](resources/UnfinishedChapters/ChL/DMDE_settings_3.PNG)

With MRT I had used 3 passes â€“ one with 2560 sector which got skipped and a 2 or 3 second timeout instead of 500ms and then a 3rd imaging pass with sector by sector reading reverse in PIO mode and 10 seconds read timeout.

Here I don't have PIO and I expect the 2nd pass to end in the middle of the night or early morning which would throw my time comparison with MRT totally off.

I decided to go straight away with 2560 sectors skip, 10 seconds of read timeout and I read the spiked sectors in reverse. This will read till the next bad sector occurs and mark all between the first and first found bad sector in reverse reading as bad. This is not perfect but it will get the job somehow done.

The imaging is occasionally painfully slow but I read basically most of the sectors:

![12.20 - USB Stabilizer second imaging pass](resources/UnfinishedChapters/ChL/imaging_2.PNG)

Finally, the USB Stabilizer and DMDE did image the first 10% of the drive in a bit less then 1,5 days and my 1 for 2 passes "hack" did cause a few more bad sectors then MRT delivered in almost exactly 1 day. 

The whole job would run approximately 15 instead of 10 days, which is really good for a tool like that. I still have maybe some room for improvement but I need to say I am impressed again by Deepspar's USB Stabilizer!

Last but not least I would recommand cooling of a drive which have to work 24h per day for multiple days to get imaged. A old case-fan and a old power-supply of a SATA to USB converter cable does this job in my lab. 


{pagebreak}
## Flash drive data recovery

Storage devices based on flash-memory need to be handled differently. To understand how data recovery for such devices works we need to understand how that devices function and how the manufacturers deal with certain limitations of that technology.

Flash drives are faster because there are no moving parts and this also eliminates any kind of mechanical failure or mechanical degradation over time. The data is stored in memory-cells in form of an electric charge. These cells degrade as data is written to them. That means the vendors have to come up with some clever ideas to prevent flash-drives from failing too soon. Strongly generalized these measures are:

 - Wearleveling which ensures that writes are distributed evenly across all memory cells
 - Obfuscation / randomisation of data to ensure there are no patterns which can cause an uneven wear within a memory-page (a group of memory-cells and the smallest unit which gets written to).
 - A good supply of spare space to replace failing memory-cells, pages or blocks (a group of pages and the smallest unit which can get erased).

### Board-level repair

First of all, we need to know if the issue is hardware- or firmware-related. The easiest approach is to repair a hardware defect like a broken connector or a blown / shorted capacitor. All you need for this is a soldering-station, tweezers and in the most cases a microscope.

### Fully encrypted devices

Then we need to distinguish between fully encrypted and obfuscated devices. Basically, all SSDs use a full hardware encryption to obfuscate and randomize data. This is also true for a tiny fraction of pendrives.

To recover data from these devices we need professional data recovery tools like
 - PC-3000 UDMA / Express with SSD plug-in (do not support NVME SSDs)
 - PC-3000 Portable III with SSD plug-in (support also NVME SSDs)
 - MRT Ultra / Express with SSD plug-in (support just a few SATA SSDs)

The process in a very generalized form is quite easy. You need to short some Pins on the SSD to put the device in so-called technology mode to allow the data recovery hardware to upload a so-called loader.

This loader will restore access to the data if the device is supported.

The good news is that many devices are nowadays based on the same controllers (e.g. Phison) but we are still very far from the over 90% success-rate a data recovery lab can reach with HDD cases.

If the device is not supported an investigator could theoretically reverse-engineer the firmware of a working model and try to find the issue. This is basically what the vendors of data recovery tools do. To do that for a single case would be an enormous amount of work and this would not fit within the budget and/or time-frame for a normal investigation. So, if the device is not supported, you are usually out of luck.

Without a somehow working firmware which handles decryption of date and the translation from LBA addresses to the correct memory location you are not able to get any data at all.

### Chip-off data recovery

Most pendrives and memory-cards do not have hardware-encryption. This is the reason why that devices can be handled in a so-called chip-off data recovery. As the name suggest memory chips get removed and we are going to read the data directly from the NAND chips.

If we do so, we have to reverse the things which are done to the data when recording. This is usually the job of the controller but if we are doing a chip-off we skip the controller and have to do his work ourself.

I will demonstrate the process with PC-3000 Flash ([https://www.acelab.eu.com/pc3000flash.php](https://www.acelab.eu.com/pc3000flash.php)) and a pendrive chip-off recovery. I choose PC-3000 Flash because Ace Lab do offer the best support in the data recovery field and PC-3000 Flash comes with a large database of already known working solutions.

This make it much easier to get started!

The only available alternative is VNR from Rusolut ([https://rusolut.com/](https://rusolut.com/)). This tool doesn't offer a database with already known solutions but the tool is very sophisticated and powerful. 

The third vendor (Flash extractor) went out of business and the tool is just available used and there is no professional support or further development anymore. That's why I would not recommend that at all.

The process is basically on all tools the same but the way how to handle a case are different. If you understand the general process, you will be able to work with each tool!

### Desoldering and preparation

First we have to desolder the memory chip:

{width: 80%}
![12.x - pendrive with one NAND chip and USBest controller](resources/UnfinishedChapters/ChL/CHIPS.JPG)

This is a very old USB pendrive with a USBest controller (model **UT163-T6**). Since the controller model was hard to read, I used a little trick. I painted the surface of the controller with a paint pen and then carefully cleaned the surface with a swab dipped in 99% isopropyl alcohol. After this only a little paint remains in the recesses on the controller and the text is very easy to read.

Here we have a **TSOP48** chip. This package has 48 legs (24 on each side) and is by far the most commonly used design for NAND chips. This is simply due to the fact that this design does not require any special additional equipment for pick-and-place machines and thus saves manufacturers additional investments.

For desoldering I use my **Yihua YH-853AAA** All-in-One Soldering Station:

![12.x - Yihua YH-853AAA with pendrive after desoldering of the chip](resources/UnfinishedChapters/ChL/DSC_4728.JPG)


