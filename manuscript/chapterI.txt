# Chapter 21 - Zff - a new forensic file format

C> By [ph0llux](https://github.com/ph0llux)

## Introducting Zff

This chapter describes the structure and design of the very recent forensic file format Zff in a very detailed way.

### What is a forensic file format? //TODO: Check Check if there is not a better heading for this...?

The most common physical objects of interest in digital forensics are probably data storage media by far.
At the same time, the data on them also takes up most of the examination time in digital forensics.
As in all other forensic disciplines, the main goal of IT forensic experts ist to analyse the data as unaltered as it can be obtained.

The most common way to obtain an unaltered state of the data you want to examine is to create a copy of them. There are two different types of such copies here: those of logical folder structure (and files) and those of all the data on the storage media themselves.
To ensure that these copies cannot be changed, they are stored as a so-called "image" (in the case of logical file system structures, this is referred to as a "logical image"; in the case of copies of all data on storage media, this is referred to as a "physical image" or "disk image"). Additional information about the creation of disk images and subtypes are described in chapter 17 in a very detailed way.
However, these "images" can be stored in different file formats and contain different additional information or meta information depending on the file format. Some known file formats are shortly considered in the following.

#### RAW (DD)

The most primitive (forensic) file format is a raw image (often also known as dd image): just a bit-by-bit copy of the entire disk, which could be created by a single ```dd``` unix-command. The data will be directly copied to the raw image and doesn't contain any metadata or additional information.
As this raw image file contains the unmodified data without any additional information to interpret, there is a wide range of tools that can be used to analyse them (even for non-forensic tools).
On the other hand some additional operations like compression, hashing, encryption, can be made and are also necessary without altering the useful content of a bit by bit copy. Additional information regarding these kind of operations has to be stored alongside the "image" itself.

#### Archive (Tar, Zip, ...)

The most primitive way to acquire logical folder structures is to store them into archives. There are several archive formats to solve this; among the most widespread are certainly GNU Tar and Zip.
With both archive formats mentioned above the folder structures as well as file contents of the files contained in the folder structures can be stored - however afterwards some file system metadata of the files are missing and also no further metadata (like hash values, etc.) can be stored - these would have to be created in separate files and then also packed into the archive.
However, the corresponding standard is missing for the last point.

#### EWF / E01

todo!()

#### AFF

todo!()

#### AFF4

todo!()

### The newcomer (Zff)

The forensic file formats presented above have a number of similarities - also with the new file format zff presented here.

#### The concepts of Zff

Zff's main goals are always speed, security and flexibility. These goals have always been the focus of every design decision and thus stand out across the entire format.
The design decisions have always been made to allow easy extensibility of the format at a later point in time - especially so that existing programming implementations can be easily extended and half the code does not have to be discarded just to enable another feature.

#### Featureset overview

##### supported compression algorithms

Since the first goal of Zff is speed, the choice of compression algorithms used in Zff excluded candidates that provide good compression ratio but slow performance. Algorithms such as LZMA are therefore not used here.

Under certain circumstances (e.g. when reading compressed data from a slow storage medium like a HDD) it may make sense to provide a better compression rate here to increase the speed (this happens when reading uncompressed data from a medium takes longer than reading compressed data from that medium + decompressing it in the CPU).
Also, it must be taken in consideration that there are algorithms that are similar in the speed of compression, but differ significantly in the speed of decompression.
Assuming that a forensic image is created only once, but is read many times (due to analysis), more focus is placed here on the speed of decompression than on compression.

Zff currently supports two "real-time" algorithms for compressing data: Zstd and Lz4.

Lz4 is widely used, a large number of implementations exist for it in different programming languages. For example, it is used in the ZFS file system for real-time compression of data, there is a native implementation in the Linux kernel, etc.
Lz4 has very high speed decompression, in most cases several GB/s per CPU core, typically limited by the speed of RAM.

Zstd is a newer compression algorithm to which meanwhile also a multiplicity of implementations in different programming languages exist. Zstd is used, for example, in the Btrfs file system for real-time compression of data, and there is also a native implementation in the Linux kernel.
Zstd has a good decompression speed, although it does not come close to Lz4. However, Zstd has compression ratios that are equal to DEFLATE (at a much higher speed). So Zstd offers the slightly better overall package and is used by default by the Zff reference implementation.

##### supported encryption

todo!()

### Terminology //TODO: may needless ... remove this section?

The appropriate terminology needed to understand how Zff works:

- **header / footer**: Zff contains several headers and footers which contain meta information about their designated assignments. E.g. there is a "compression header" which contains the appropriate information about the used compression method or the compression level. 

- **segment**: Zff containers can be stored split - into several individual files. To read the data in the appropriate container "files" in an efficient way, zff has its own implementation to segment its container - the individual files obtained after splitting a container are called "segments".

- **object**: A zff container can store multiple images in a single container. Each image (physical or logical) is called "object".

- **chunk**: The input data is read in parts and also stored as such "parts". These "parts" are called "chunks" and can be stored compressed and/or encrypted, if necessary. The entire process is called "chunking" and will be discussed in detail in a later subsection.

### The general layout



## References

[] https://facebook.github.io/zstd/